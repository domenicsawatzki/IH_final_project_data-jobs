{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from webscraper.scrap_modules import my_NLP as myNLP \n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Code - NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load cleaned dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"webscraper/cleaned_data/cleaned_dataframe.pkl\", \"rb\") as file:\n",
    "    df = pickle.load(file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>city</th>\n",
       "      <th>posting_date</th>\n",
       "      <th>job_description</th>\n",
       "      <th>seniority_level</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>job_function</th>\n",
       "      <th>industries</th>\n",
       "      <th>scraping_date</th>\n",
       "      <th>url</th>\n",
       "      <th>keyword</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3685669741</td>\n",
       "      <td>Software Engineer Fullstack (m/w/d)</td>\n",
       "      <td>Atruvia AG</td>\n",
       "      <td>Aschheim, Bavaria, Germany</td>\n",
       "      <td>1 day ago</td>\n",
       "      <td>VollzeitWir sind der Digitalisierungspartner d...</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Engineering and Information Technology</td>\n",
       "      <td>IT Services and IT Consulting</td>\n",
       "      <td>2023-09-24</td>\n",
       "      <td>https://www.linkedin.com/jobs/search?keywords=...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3719620327</td>\n",
       "      <td>Data Analyst - Business Intelligence</td>\n",
       "      <td>Almedia</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "      <td>5 days ago</td>\n",
       "      <td>Almedia helps companies grow by promoting thei...</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>Technology, Information and Internet</td>\n",
       "      <td>2023-09-24</td>\n",
       "      <td>https://www.linkedin.com/jobs/search?keywords=...</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                 title     company  \\\n",
       "0  3685669741   Software Engineer Fullstack (m/w/d)  Atruvia AG   \n",
       "1  3719620327  Data Analyst - Business Intelligence     Almedia   \n",
       "\n",
       "                         city posting_date  \\\n",
       "0  Aschheim, Bavaria, Germany    1 day ago   \n",
       "1     Berlin, Berlin, Germany   5 days ago   \n",
       "\n",
       "                                     job_description   seniority_level  \\\n",
       "0  VollzeitWir sind der Digitalisierungspartner d...       Entry level   \n",
       "1  Almedia helps companies grow by promoting thei...  Mid-Senior level   \n",
       "\n",
       "  employment_type                            job_function  \\\n",
       "0       Full-time  Engineering and Information Technology   \n",
       "1       Full-time                                 Analyst   \n",
       "\n",
       "                             industries scraping_date  \\\n",
       "0         IT Services and IT Consulting    2023-09-24   \n",
       "1  Technology, Information and Internet    2023-09-24   \n",
       "\n",
       "                                                 url         keyword language  \n",
       "0  https://www.linkedin.com/jobs/search?keywords=...  Data Scientist       de  \n",
       "1  https://www.linkedin.com/jobs/search?keywords=...    Data Analyst       en  "
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keyword Extraction \n",
    "https://www.analyticsvidhya.com/blog/2022/03/keyword-extraction-methods-from-documents-in-nlp/#:~:text=Textrank%20is%20a%20Python%20tool,compatible%20with%20the%20Spacy%20pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "import pytextrank \n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# !spacy download en_core_web_sm\n",
    "# !spacy download de_core_news_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### first cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_df = pd.DataFrame(df) # create a new data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>city</th>\n",
       "      <th>posting_date</th>\n",
       "      <th>job_description</th>\n",
       "      <th>seniority_level</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>job_function</th>\n",
       "      <th>industries</th>\n",
       "      <th>scraping_date</th>\n",
       "      <th>url</th>\n",
       "      <th>keyword</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3685669741</td>\n",
       "      <td>Software Engineer Fullstack (m/w/d)</td>\n",
       "      <td>Atruvia AG</td>\n",
       "      <td>Aschheim, Bavaria, Germany</td>\n",
       "      <td>1 day ago</td>\n",
       "      <td>VollzeitWir sind der Digitalisierungspartner d...</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Engineering and Information Technology</td>\n",
       "      <td>IT Services and IT Consulting</td>\n",
       "      <td>2023-09-24</td>\n",
       "      <td>https://www.linkedin.com/jobs/search?keywords=...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3719620327</td>\n",
       "      <td>Data Analyst - Business Intelligence</td>\n",
       "      <td>Almedia</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "      <td>5 days ago</td>\n",
       "      <td>Almedia helps companies grow by promoting thei...</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>Technology, Information and Internet</td>\n",
       "      <td>2023-09-24</td>\n",
       "      <td>https://www.linkedin.com/jobs/search?keywords=...</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3720365801</td>\n",
       "      <td>(Junior) Data Engineer (m/f/d)</td>\n",
       "      <td>Sandbox Interactive</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "      <td>1 day ago</td>\n",
       "      <td>YOUR GAMEBuild and maintain the current data i...</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Computer Games</td>\n",
       "      <td>2023-09-24</td>\n",
       "      <td>https://www.linkedin.com/jobs/search?keywords=...</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3672508925</td>\n",
       "      <td>Financial Data Analyst (m/f/d)</td>\n",
       "      <td>Ultramarin</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "      <td>2 months ago</td>\n",
       "      <td>About The PositionWe are looking for a top-tie...</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>2023-09-24</td>\n",
       "      <td>https://www.linkedin.com/jobs/search?keywords=...</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3695466781</td>\n",
       "      <td>Business Intelligence Analyst (f/m/d)</td>\n",
       "      <td>Les Lunes</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "      <td>4 weeks ago</td>\n",
       "      <td>Your missionAs a Business Intelligence Analyst...</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Research, Analyst, and Information Technology</td>\n",
       "      <td>Retail Apparel and Fashion</td>\n",
       "      <td>2023-09-24</td>\n",
       "      <td>https://www.linkedin.com/jobs/search?keywords=...</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3585738180</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Orange Quarter</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "      <td>5 months ago</td>\n",
       "      <td>Orange Quarter are working with an exciting st...</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Staffing and Recruiting</td>\n",
       "      <td>2023-09-24</td>\n",
       "      <td>https://www.linkedin.com/jobs/search?keywords=...</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3585734564</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Orange Quarter</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "      <td>5 months ago</td>\n",
       "      <td>Orange Quarter are currently looking for a Dat...</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Staffing and Recruiting</td>\n",
       "      <td>2023-09-24</td>\n",
       "      <td>https://www.linkedin.com/jobs/search?keywords=...</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3704916810</td>\n",
       "      <td>BI Analyst (f/m/d)</td>\n",
       "      <td>Enter</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "      <td>3 weeks ago</td>\n",
       "      <td>Build the future with Enter.Our mission is to ...</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Architecture and Planning</td>\n",
       "      <td>2023-09-24</td>\n",
       "      <td>https://www.linkedin.com/jobs/search?keywords=...</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3585734595</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Orange Quarter</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "      <td>5 months ago</td>\n",
       "      <td>We are currently working with an emerging SaaS...</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Staffing and Recruiting</td>\n",
       "      <td>2023-09-24</td>\n",
       "      <td>https://www.linkedin.com/jobs/search?keywords=...</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3698396795</td>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Klim</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "      <td>1 month ago</td>\n",
       "      <td>We are Klim, a Berlin-based clean-tech company...</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Other</td>\n",
       "      <td>IT Services and IT Consulting</td>\n",
       "      <td>2023-09-24</td>\n",
       "      <td>https://www.linkedin.com/jobs/search?keywords=...</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                  title              company  \\\n",
       "0  3685669741    Software Engineer Fullstack (m/w/d)           Atruvia AG   \n",
       "1  3719620327   Data Analyst - Business Intelligence              Almedia   \n",
       "2  3720365801         (Junior) Data Engineer (m/f/d)  Sandbox Interactive   \n",
       "3  3672508925         Financial Data Analyst (m/f/d)           Ultramarin   \n",
       "4  3695466781  Business Intelligence Analyst (f/m/d)            Les Lunes   \n",
       "5  3585738180                           Data Analyst       Orange Quarter   \n",
       "6  3585734564                           Data Analyst       Orange Quarter   \n",
       "7  3704916810                     BI Analyst (f/m/d)                Enter   \n",
       "8  3585734595                           Data Analyst       Orange Quarter   \n",
       "9  3698396795                    Senior Data Analyst                 Klim   \n",
       "\n",
       "                         city  posting_date  \\\n",
       "0  Aschheim, Bavaria, Germany     1 day ago   \n",
       "1     Berlin, Berlin, Germany    5 days ago   \n",
       "2     Berlin, Berlin, Germany     1 day ago   \n",
       "3     Berlin, Berlin, Germany  2 months ago   \n",
       "4     Berlin, Berlin, Germany   4 weeks ago   \n",
       "5     Berlin, Berlin, Germany  5 months ago   \n",
       "6     Berlin, Berlin, Germany  5 months ago   \n",
       "7     Berlin, Berlin, Germany   3 weeks ago   \n",
       "8     Berlin, Berlin, Germany  5 months ago   \n",
       "9     Berlin, Berlin, Germany   1 month ago   \n",
       "\n",
       "                                     job_description   seniority_level  \\\n",
       "0  VollzeitWir sind der Digitalisierungspartner d...       Entry level   \n",
       "1  Almedia helps companies grow by promoting thei...  Mid-Senior level   \n",
       "2  YOUR GAMEBuild and maintain the current data i...  Mid-Senior level   \n",
       "3  About The PositionWe are looking for a top-tie...  Mid-Senior level   \n",
       "4  Your missionAs a Business Intelligence Analyst...  Mid-Senior level   \n",
       "5  Orange Quarter are working with an exciting st...       Entry level   \n",
       "6  Orange Quarter are currently looking for a Dat...       Entry level   \n",
       "7  Build the future with Enter.Our mission is to ...  Mid-Senior level   \n",
       "8  We are currently working with an emerging SaaS...       Entry level   \n",
       "9  We are Klim, a Berlin-based clean-tech company...  Mid-Senior level   \n",
       "\n",
       "  employment_type                                   job_function  \\\n",
       "0       Full-time         Engineering and Information Technology   \n",
       "1       Full-time                                        Analyst   \n",
       "2       Full-time                         Information Technology   \n",
       "3       Full-time                         Information Technology   \n",
       "4       Full-time  Research, Analyst, and Information Technology   \n",
       "5       Full-time                         Information Technology   \n",
       "6       Full-time                         Information Technology   \n",
       "7       Full-time                         Information Technology   \n",
       "8       Full-time                         Information Technology   \n",
       "9       Full-time                                          Other   \n",
       "\n",
       "                             industries scraping_date  \\\n",
       "0         IT Services and IT Consulting    2023-09-24   \n",
       "1  Technology, Information and Internet    2023-09-24   \n",
       "2                        Computer Games    2023-09-24   \n",
       "3                    Financial Services    2023-09-24   \n",
       "4            Retail Apparel and Fashion    2023-09-24   \n",
       "5               Staffing and Recruiting    2023-09-24   \n",
       "6               Staffing and Recruiting    2023-09-24   \n",
       "7             Architecture and Planning    2023-09-24   \n",
       "8               Staffing and Recruiting    2023-09-24   \n",
       "9         IT Services and IT Consulting    2023-09-24   \n",
       "\n",
       "                                                 url         keyword language  \n",
       "0  https://www.linkedin.com/jobs/search?keywords=...  Data Scientist       de  \n",
       "1  https://www.linkedin.com/jobs/search?keywords=...    Data Analyst       en  \n",
       "2  https://www.linkedin.com/jobs/search?keywords=...    Data Analyst       en  \n",
       "3  https://www.linkedin.com/jobs/search?keywords=...    Data Analyst       en  \n",
       "4  https://www.linkedin.com/jobs/search?keywords=...    Data Analyst       en  \n",
       "5  https://www.linkedin.com/jobs/search?keywords=...    Data Analyst       en  \n",
       "6  https://www.linkedin.com/jobs/search?keywords=...    Data Analyst       en  \n",
       "7  https://www.linkedin.com/jobs/search?keywords=...    Data Analyst       en  \n",
       "8  https://www.linkedin.com/jobs/search?keywords=...    Data Analyst       en  \n",
       "9  https://www.linkedin.com/jobs/search?keywords=...    Data Analyst       en  "
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 22079/22079 [00:00<00:00, 152467.04it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "tqdm.pandas(desc=\"Processing\")\n",
    "nlp_df['cp1_title'] = nlp_df[\"title\"].progress_apply(myNLP.clean_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove text in parentheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 22079/22079 [00:00<00:00, 714249.65it/s]\n",
      "Processing: 100%|██████████| 22079/22079 [00:00<00:00, 1336480.03it/s]\n",
      "Processing: 100%|██████████| 22079/22079 [00:00<00:00, 655015.12it/s]\n"
     ]
    }
   ],
   "source": [
    "pattern_to_extract = r'\\((.*?)\\)'\n",
    "\n",
    "# Extract text within parentheses and put it in a new column\n",
    "nlp_df['text_in_parentheses'] = nlp_df['cp1_title'].progress_apply(lambda x: re.findall(pattern_to_extract, x))\n",
    "\n",
    "# Convert lists with only one element to that element, and keep lists for multiple elements\n",
    "nlp_df['text_in_parentheses'] = nlp_df['text_in_parentheses'].progress_apply(lambda x: x[0] if len(x) == 1 else x)\n",
    "\n",
    "# Remove the text within parentheses \n",
    "nlp_df['cp1_title'] = nlp_df['cp1_title'].progress_apply(lambda x: re.sub(pattern_to_extract, '', x).strip())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize, lemmatize, remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 22079/22079 [00:01<00:00, 15357.63it/s]\n",
      "Processing: 100%|██████████| 22079/22079 [00:44<00:00, 497.57it/s]\n",
      "Processing: 100%|██████████| 22079/22079 [00:50<00:00, 437.99it/s]\n",
      "Processing: 100%|██████████| 22079/22079 [00:00<00:00, 930237.14it/s]\n"
     ]
    }
   ],
   "source": [
    "nlp_df['cp2_title'] = nlp_df['cp1_title'].progress_apply(myNLP.tokenize)\n",
    "nlp_df['cp2_title'] = nlp_df['cp2_title'].progress_apply(myNLP.stem_and_lemmatize)\n",
    "nlp_df['cp2_title'] = nlp_df['cp2_title'].progress_apply(myNLP.remove_stopwords)\n",
    "nlp_df['cp2_title'] = nlp_df['cp2_title'].progress_apply(myNLP.re_blob) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### clean dataframe based on several rounds of inspecting word clouds \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_df_clean = pd.DataFrame(nlp_df) # load data\n",
    "\n",
    "nlp_df_clean.to_csv(\"test_nlp_dataframe.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 22079/22079 [00:09<00:00, 2361.37it/s]\n"
     ]
    }
   ],
   "source": [
    "nlp_df_clean = nlp_df_clean.progress_apply(myNLP.extract_level, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job_level\n",
       "NaN              12417\n",
       "manager_level     3217\n",
       "senior_level      3184\n",
       "consultant        1873\n",
       "student_level     1043\n",
       "junior_level       345\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_df_clean['job_level'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job_level\n",
       "NaN             12417\n",
       "consultant       1873\n",
       "junior_level      345\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_df_clean = nlp_df_clean[~nlp_df_clean['job_level'].isin(['senior_level', 'student_level', 'manager_level'])]\n",
    "nlp_df_clean['job_level'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 14635/14635 [00:00<00:00, 20960.58it/s]\n"
     ]
    }
   ],
   "source": [
    "nlp_df_clean['cp2_title'] = nlp_df_clean['cp2_title'].progress_apply(myNLP.combine_keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tokenize again after combining the keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp_df_clean['cp2_title'] = nlp_df_clean['cp2_title'].progress_apply(myNLP.tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extract new job title with combined keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 14635/14635 [00:05<00:00, 2578.05it/s]\n"
     ]
    }
   ],
   "source": [
    "nlp_df_clean = nlp_df_clean.progress_apply(myNLP.extract_keywords, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      NaN\n",
       "1           [data_analyst]\n",
       "2          [data_engineer]\n",
       "3           [data_analyst]\n",
       "4                      NaN\n",
       "               ...        \n",
       "22070     [sap_specialist]\n",
       "22072      [test_engineer]\n",
       "22074    [devops_engineer]\n",
       "22075                  NaN\n",
       "22078                  NaN\n",
       "Name: new_job_title, Length: 14635, dtype: object"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_df_clean['new_job_title']."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_df_clean['cp2_title'] = nlp_df_clean['cp2_title'].progress_apply(myNLP.drop_words)\n",
    "myNLP.word_cloud(nlp_df_clean, 'cp2_title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nlp_df_clean.shape)\n",
    "nlp_df_split = nlp_df_clean[nlp_df_clean['new_job_title'].isna()]\n",
    "\n",
    "print(nlp_df_split.shape)\n",
    "\n",
    "all_text = nlp_df_split['cp2_title']\n",
    "\n",
    "bag = \" \".join(all_text) # combining all job title "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### word cloud "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myNLP.word_cloud(nlp_df_split, 'cp2_title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keybert import KeyBERT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yake keyword extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yake\n",
    "\n",
    "kw_extractor = yake.KeywordExtractor()\n",
    "keywords = kw_extractor.extract_keywords(bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kw in keywords:\n",
    "    print(kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature extraction:TF-IDF (Term Frequency-Inverse Document Frequency) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Data Preprocessing\n",
    "## Lowercasing\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def tokenize_stemm_vectorize(df):\n",
    "## Tokenization and Removing Stop Words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    df['cp2_title'] = df['cp2_title'].apply(lambda x: ' '.join([word for word in word_tokenize(x) if word.lower() not in stop_words]))\n",
    "\n",
    "    ## Stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    df['cp2_title'] = df['cp2_title'].apply(lambda x: ' '.join([stemmer.stem(word) for word in word_tokenize(x)]))\n",
    "\n",
    "    # Step 2: Text Vectorization\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(df['cp2_title'])\n",
    "    \n",
    "    return X\n",
    "\n",
    "X = tokenize_stemm_vectorize(nlp_df_split)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Step 4: Evaluation\n",
    "# Manually evaluate the clusters or use metrics\n",
    "\n",
    "# Step 5: Visualization (Optional)\n",
    "# Use Matplotlib or Seaborn to visualize clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Elbow Method to find optimal K\n",
    "# inertia = []\n",
    "# for i in range(1, 30):\n",
    "#     kmeans = KMeans(n_clusters=i, init='k-means++')\n",
    "#     kmeans.fit(X)\n",
    "#     inertia.append(kmeans.inertia_)\n",
    "\n",
    "# plt.plot(range(1, 11), inertia)\n",
    "# plt.title('Elbow Method')\n",
    "# plt.xlabel('Number of clusters')\n",
    "# plt.ylabel('Inertia')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model: KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize variables\n",
    "silhouette_scores = []\n",
    "inertia = []\n",
    "# Loop through different numbers of clusters\n",
    "for i in range(10, 30):  # Start from 2 as silhouette_score needs at least 2 clusters\n",
    "    kmeans = KMeans(n_clusters=i, init='k-means++')\n",
    "    kmeans.fit(X)\n",
    "    cluster_labels = kmeans.labels_\n",
    "    \n",
    "    inertia.append(kmeans.inertia_)\n",
    "    \n",
    "    # Calculate the silhouette score and append to the list\n",
    "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "    silhouette_scores.append(silhouette_avg)\n",
    "    # print(f\"For n_clusters = {i}, the silhouette score is {silhouette_avg}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plotting the silhouette scores\n",
    "plt.plot(range(10, 30), silhouette_scores)\n",
    "plt.title('Silhouette Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(range(10, 30), inertia)\n",
    "plt.title('Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Clustering\n",
    "kmeans = KMeans(n_clusters=26)  # Assuming 5 clusters\n",
    "kmeans.fit(X)\n",
    "nlp_df_split['cluster_kmeans'] = kmeans.labels_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmean_groups = nlp_df_split[['id', 'cp2_title', 'cluster_kmeans']]\n",
    "\n",
    "with open(\"webscraper/model_data/kmean_groups_v2.csv\", \"wb\") as file:\n",
    "    kmean_groups.to_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmean_model1 = {\"dataframe\":nlp_df_split,\n",
    "                \"X\":X,\n",
    "                'Prediction':kmean_groups}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Model: naive_bayes / MultinomialNB -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# clf = MultinomialNB()\n",
    "# clf.fit(X)\n",
    "# nlp_df_split['cluster_naive_bayes'] = clf.predict(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "manually reserach: filter specific words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myNLP.word_cloud(nlp_df_split, 'cp2_title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = nlp_df_split[nlp_df_split['cp2_title'].str.contains(\"software\", case=False)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df[['cp2_title', 'cp1_title','title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df['cp1_title'] = filtered_df['cp1_title'].progress_apply(myNLP.combine_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = filtered_df.progress_apply(myNLP.extract_keywords, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df[['cp2_title', 'cp1_title','title', 'new_job_title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyst, berlin, past week, 25km - https://www.linkedin.com/jobs/search?keywords=Data%20Analyst&location=Berlin%2C%20Berlin%2C%20Germany&locationId=&geoId=106967730&f_TPR=r604800&distance=25&position=1&pageNum=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['data_analyst', 'ml_engineer', 'it_systemadmin', 'software_developer','scientist_','research_scientist', 'data_architect','java_software_engineer','data_engineer', 'database_datawarehouse', 'business_analyst', 'product_analyst', \n",
    "                'business_intelligence_analyst', 'full_stack', 'database_administrator', 'fp&a_analyst', 'product_analyst'\n",
    "                'programm_manager', 'data_analytics', 'big_data_engineer/specialist', 'sap_specialist', 'devops_engineer', 'backend_developer', 'data_management'\n",
    "               'software_engineer', 'analysis_engineer', 'data_scientist', 'machine_learning_engineer', 'ai_engineer', 'controlling_', 'it_systemadmin'\n",
    "               'cloud_engineer', 'deep_learning', 'reporting_analyst', 'test_engineer', 'system_engineer', 'specialist', 'sap_specialist']\n",
    "\n",
    "\n",
    "for key in keywords:\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
