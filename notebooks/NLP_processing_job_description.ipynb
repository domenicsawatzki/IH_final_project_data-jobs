{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Domen\\IronHack\\01_projects\\IH_final_project_data-jobs\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n",
    "import os \n",
    "\n",
    "os.chdir('c:/Users/Domen/IronHack/01_projects/IH_final_project_data-jobs')\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from src.myModules import my_NLP as myNLP\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Domen\\IronHack\\01_projects\\IH_final_project_data-jobs\n",
      "data/NLP_data/\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "with open(\"config/config.json\", 'r') as f:\n",
    "    config = json.load(f)\n",
    "    \n",
    "NLP_data_path = config['NLP_data_path']\n",
    "\n",
    "print(NLP_data_path)\n",
    "\n",
    "\n",
    "nlp_df_input = 'NLP_title'\n",
    "nlp_df_output_name = 'skills_df'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Code - NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load cleaned dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{NLP_data_path}{nlp_df_input}.pkl\", \"rb\") as file:\n",
    "    df = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_job_title</th>\n",
       "      <th>count_values</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[software_engineer]</td>\n",
       "      <td>1</td>\n",
       "      <td>3685669741</td>\n",
       "      <td>Software Engineer Fullstack (m/w/d)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[data_analyst, bi_analyst]</td>\n",
       "      <td>2</td>\n",
       "      <td>3719620327</td>\n",
       "      <td>Data Analyst - Business Intelligence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[data_engineer]</td>\n",
       "      <td>1</td>\n",
       "      <td>3720365801</td>\n",
       "      <td>(Junior) Data Engineer (m/f/d)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[data_analyst]</td>\n",
       "      <td>1</td>\n",
       "      <td>3672508925</td>\n",
       "      <td>Financial Data Analyst (m/f/d)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[bi_analyst]</td>\n",
       "      <td>1</td>\n",
       "      <td>3695466781</td>\n",
       "      <td>Business Intelligence Analyst (f/m/d)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29297</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>3728033397</td>\n",
       "      <td>Softwareingenieur:in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29298</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>3671825428</td>\n",
       "      <td>Junior Teamlead Delivery Risk Reporting (m/w/d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29299</th>\n",
       "      <td>[data_analyst]</td>\n",
       "      <td>1</td>\n",
       "      <td>3719993773</td>\n",
       "      <td>Big Data Analystin / Analyst (w/m/d)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29300</th>\n",
       "      <td>[software_developer]</td>\n",
       "      <td>1</td>\n",
       "      <td>3699632487</td>\n",
       "      <td>(Junior) Developer (all genders)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29301</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>3688010392</td>\n",
       "      <td>Demand Planner Germany (m/f/d)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29302 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    new_job_title  count_values          id  \\\n",
       "0             [software_engineer]             1  3685669741   \n",
       "1      [data_analyst, bi_analyst]             2  3719620327   \n",
       "2                 [data_engineer]             1  3720365801   \n",
       "3                  [data_analyst]             1  3672508925   \n",
       "4                    [bi_analyst]             1  3695466781   \n",
       "...                           ...           ...         ...   \n",
       "29297                                         0  3728033397   \n",
       "29298                                         0  3671825428   \n",
       "29299              [data_analyst]             1  3719993773   \n",
       "29300        [software_developer]             1  3699632487   \n",
       "29301                                         0  3688010392   \n",
       "\n",
       "                                                   title  \n",
       "0                    Software Engineer Fullstack (m/w/d)  \n",
       "1                   Data Analyst - Business Intelligence  \n",
       "2                         (Junior) Data Engineer (m/f/d)  \n",
       "3                         Financial Data Analyst (m/f/d)  \n",
       "4                  Business Intelligence Analyst (f/m/d)  \n",
       "...                                                  ...  \n",
       "29297                               Softwareingenieur:in  \n",
       "29298  Junior Teamlead Delivery Risk Reporting (m/w/d...  \n",
       "29299               Big Data Analystin / Analyst (w/m/d)  \n",
       "29300                   (Junior) Developer (all genders)  \n",
       "29301                     Demand Planner Germany (m/f/d)  \n",
       "\n",
       "[29302 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_job_title</th>\n",
       "      <th>count_values</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14650</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>3724919518</td>\n",
       "      <td>CONTAINER PLATFORM ENGINEER(ALL GENDERS)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16468</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>3713484266</td>\n",
       "      <td>Fachinformatiker (w/m/d) für Systemintegration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16465</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>3713703765</td>\n",
       "      <td>Principal Engineer (m/f/x) - Foreign Exchange ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16464</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>3715320605</td>\n",
       "      <td>Mitarbeiter/in im technischen Kundensupport (w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16463</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>3706058144</td>\n",
       "      <td>Business Expert Data &amp; Process Management (m/f/x)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4306</th>\n",
       "      <td>[ai_engineer, big_data_engineer/specialist, ja...</td>\n",
       "      <td>4</td>\n",
       "      <td>3715658593</td>\n",
       "      <td>Senior AI Architect - Python / Big Data / Java...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5945</th>\n",
       "      <td>[cloud_engineer, software_developer, it_system...</td>\n",
       "      <td>5</td>\n",
       "      <td>3725476793</td>\n",
       "      <td>Cloud-Developer (m/w/d) mit Managementerfahrun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21214</th>\n",
       "      <td>[cloud_engineer, software_developer, it_system...</td>\n",
       "      <td>5</td>\n",
       "      <td>3727809960</td>\n",
       "      <td>Cloud-Developer (m/w/d) mit Managementerfahrun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19923</th>\n",
       "      <td>[it_systemadmin, sap_specialist, sap_specialis...</td>\n",
       "      <td>5</td>\n",
       "      <td>3713095897</td>\n",
       "      <td>Business Unit Lead SAP BI - SAP BW on HANA, BW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7719</th>\n",
       "      <td>[it_systemadmin, sap_specialist, sap_specialis...</td>\n",
       "      <td>5</td>\n",
       "      <td>3722169653</td>\n",
       "      <td>IT Manager Business Analytics (m/w/d) - Inform...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29302 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           new_job_title  count_values  \\\n",
       "14650                                                                0   \n",
       "16468                                                                0   \n",
       "16465                                                                0   \n",
       "16464                                                                0   \n",
       "16463                                                                0   \n",
       "...                                                  ...           ...   \n",
       "4306   [ai_engineer, big_data_engineer/specialist, ja...             4   \n",
       "5945   [cloud_engineer, software_developer, it_system...             5   \n",
       "21214  [cloud_engineer, software_developer, it_system...             5   \n",
       "19923  [it_systemadmin, sap_specialist, sap_specialis...             5   \n",
       "7719   [it_systemadmin, sap_specialist, sap_specialis...             5   \n",
       "\n",
       "               id                                              title  \n",
       "14650  3724919518           CONTAINER PLATFORM ENGINEER(ALL GENDERS)  \n",
       "16468  3713484266     Fachinformatiker (w/m/d) für Systemintegration  \n",
       "16465  3713703765  Principal Engineer (m/f/x) - Foreign Exchange ...  \n",
       "16464  3715320605  Mitarbeiter/in im technischen Kundensupport (w...  \n",
       "16463  3706058144  Business Expert Data & Process Management (m/f/x)  \n",
       "...           ...                                                ...  \n",
       "4306   3715658593  Senior AI Architect - Python / Big Data / Java...  \n",
       "5945   3725476793  Cloud-Developer (m/w/d) mit Managementerfahrun...  \n",
       "21214  3727809960  Cloud-Developer (m/w/d) mit Managementerfahrun...  \n",
       "19923  3713095897  Business Unit Lead SAP BI - SAP BW on HANA, BW...  \n",
       "7719   3722169653  IT Manager Business Analytics (m/w/d) - Inform...  \n",
       "\n",
       "[29302 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Technical Lead Developer | Cloud Service Platform | Java, Spring, Cloud | Up to €105k\n",
      "IT System Engineer / IT Systemadministrator (*)\n",
      "Senior AI Architect - Python / Big Data / Java / Backend / Home Office (w/m/d)\n",
      "IT Service Manager SAP Basis & SAP Cloud (m/w/d) – Wiesbaden, Competitive Benefits Package + Chance to join one of Germany’s Leading Brands\n",
      "Fullstack Software Engineer - Cloud / DevOps / Git / Home Office (m/w/d)\n",
      "Fullstack Software Engineer - Cloud / DevOps / Git / Home Office (m/w/d)\n",
      "Software Engineer / IT Consultant - MSc/PhD Graduates / Python / Java  / JavaScript / C/C++ / C# / PHP / SCRUM\n",
      "Business Intelligence Developer mit Schwerpunkt ETL / Data Warehouse (m/w/d)\n",
      "IT Manager – IT Product Manager / IT Engineering / Data Analytics (m/f/d)\n",
      "SAP S/4HANA M&A IT SAP Cloud Architect (m/f/x) in Frankfurt (Main)\n",
      "Consultant SAP Analytics - SAP Data Warehouse / Business Intelligence (m/w/d)\n",
      "Fullstack Software Engineer - Cloud / DevOps / Git / Home Office (m/w/d)\n",
      "Fullstack Developer - JAva / JUnit / Datenbanken / Rest (m/w/d)\n",
      "Data Engineer - Business Intelligence / IT Beratung / SAP ERP / ABAP (m/w/d)\n",
      "Senior AI Architect - Python / Big Data / Java / Backend / Home Office (w/m/d)\n",
      "Senior AI Architect - Python / Big Data / Java / Backend / Home Office (w/m/d)\n",
      "Business Unit Lead SAP BI - SAP BW on HANA, BW/4HANA, SAP Analytics Cloud (m/w/d)\n",
      "Cloud-Developer (m/w/d) mit Managementerfahrung gesucht - wachse mit DIU | Vollzeit oder 4 Tage | Hybrid oder Remote\n",
      "Cloud-Developer (m/w/d) mit Managementerfahrung gesucht - wachse mit DIU | Vollzeit oder 4 Tage | Hybrid oder Remote\n",
      "IT Manager Business Analytics (m/w/d) - Informatiker, Wirtschaftsinformatiker o. ä. - Schwerpunkt SAP BW/4HANA, SAP Business Objects, SAP Analytics Cloud und MS Power BI\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "df.fillna(\"\", inplace=True)\n",
    "df['count_values'] = df['new_job_title'].apply(len)\n",
    "original_column_with_counts = df[['new_job_title', 'count_values','id', 'title']]\n",
    "\n",
    "display(original_column_with_counts)\n",
    "\n",
    "original_column_with_counts[\"count_values\"]\n",
    "\n",
    "sorted_df = original_column_with_counts.sort_values(by='count_values')\n",
    "display(sorted_df)\n",
    "\n",
    "\n",
    "sorted_df = sorted_df.sort_values(by='count_values')\n",
    "\n",
    "# Get the last 20 entries\n",
    "last_20_entries = sorted_df.tail(20)\n",
    "\n",
    "# Print the 'title' values for the last 20 entries\n",
    "titles_to_print = last_20_entries['title'].tolist()\n",
    "\n",
    "for title in titles_to_print:\n",
    "    print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_df = df[df['first_match']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)\n",
    "nlp_df = df[df['first_match']==True]\n",
    "\n",
    "# nlp_df = nlp_df[[ 'id', 'company', 'title','new_job_title', 'job_description',  'language', 'url']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['data_analyst', 'analytics_engineer','bi_analyst', 'ml_engineer', 'business_analyst', 'business_intelligence_analyst', 'data_scientist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_df = nlp_df[nlp_df['new_job_title'].apply(lambda job_title: any(skill in keywords for skill in job_title))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_df.fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Language detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tricky_re_skills = ['r', 'scala', 'sas', 'gcp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skills = ['python', 'sql', 'gitlab',' r ','bi-bool','r shiny', 'power bi', 'visual analytics' 'cognos bi','aws', 'spark', 'azure', 'tableau', 'java', 'excel', 'hadoop', 'scala', \n",
    "           'snowflake', 'kafka', 'nosql', 'databricks', ' git ', 'redshift', 'airflow', 'oracle', 'sap', 'ad-hoc', \n",
    "           'sql server', 'docker', 'kubernetes', 'power_bi', 'c++', 'numpy', 'dplyr', 'matplotlib', \n",
    "           'seaborn', 'ggplot', 'hypothesis testing', 'regression analysis', 'predictive analysis', 'bayesian statistics', \n",
    "           'scikit', 'tensorflow', 'pytorch', 'xgboost', 'deep learning', 'hadoop', 'bigquery', 'airflow', 'nltk', 'spacy', \n",
    "           'nlp', 'aws', 'azure', 'looker', 'ms-office', ' ml ', ' nlp ', ' pandas', 'e2e', ' sas ', ' gcp ']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First round of skill extraction from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas(desc=\"Processing\")\n",
    "nlp_df['nlp_job_description'] = nlp_df['job_description'].progress_apply(lambda x: x.lower().strip()) # lower job description text\n",
    "nlp_df = nlp_df.progress_apply(lambda row: myNLP.check_skills(row, skills), axis=1) # use check_skill function to extract skills from text which matches words in skills list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(nlp_df.loc[nlp_df[\"city\"]==38])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_df = myNLP.prepare_dataset(nlp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f\"{NLP_data_path}{nlp_df_output_name}.pkl\", \"wb\") as file:\n",
    "#     pickle.dump(nlp_df, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{NLP_data_path}{nlp_df_output_name}.csv\", \"wb\") as file:\n",
    "    nlp_df.to_csv(file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigate german and english text to identify further skills to extract "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_view = nlp_df[nlp_df['new_job_title'].apply(lambda job_title: any(skill in ['data_analyst'] for skill in job_title))] # filter dataset on specific job title\n",
    "filtered_view.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ger = nlp_df[nlp_df['language'] == 'de']\n",
    "df_eng = nlp_df[nlp_df['language'] == 'en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ger.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ger = df_ger.progress_apply(lambda row: myNLP.check_german_style(row), axis=1)\n",
    "# df_ger.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ger['nlp_job_description'] = df_ger['nlp_job_description'].progress_apply(myNLP.clean_up)\n",
    "df_ger['nlp_job_description'] = df_ger['nlp_job_description'].progress_apply(myNLP.stem_and_lemmatize_german) # lemmatize strings\n",
    "df_ger['nlp_job_description'] = df_ger['nlp_job_description'].progress_apply(myNLP.tokenize) # tokenize\n",
    "df_ger['nlp_job_description'] = df_ger['nlp_job_description'].progress_apply(myNLP.remove_stopwords_german) #remove stopwords from\n",
    "df_ger['nlp_job_description'] = df_ger['nlp_job_description'].progress_apply(myNLP.re_blob) # reblob\n",
    "df_ger['nlp_job_description'] = df_ger['nlp_job_description'].progress_apply(lambda x: x.lower().strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ger['nlp_job_description'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myNLP.word_cloud(df_ger, 'nlp_job_description')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "english dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng['nlp_job_description'] = df_eng['nlp_job_description'].progress_apply(myNLP.clean_up) # clean dataset\n",
    "df_eng['nlp_job_description'] = df_eng['nlp_job_description'].progress_apply(myNLP.stem_and_lemmatize_german) # lemmatize strings\n",
    "df_eng['nlp_job_description'] = df_eng['nlp_job_description'].progress_apply(myNLP.tokenize) # tokenize\n",
    "df_eng['nlp_job_description'] = df_eng['nlp_job_description'].progress_apply(myNLP.remove_stopwords_german) #remove stopwords from\n",
    "df_eng['nlp_job_description'] = df_eng['nlp_job_description'].progress_apply(myNLP.re_blob) # reblob\n",
    "df_eng['nlp_job_description'] = df_eng['nlp_job_description'].progress_apply(lambda x: x.lower().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_eng['nlp_job_description'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myNLP.word_cloud(df_eng, 'nlp_job_description')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clustering using BERT Model and KMEAN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "from sklearn.cluster import KMeans \n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "model = BertModel.from_pretrained('bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(\"data/model_data/bert_embedding.pkl\", \"wb\") as file:\n",
    "        pickle.dump(embeddings, file)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(\"data/model_data/bert_embedding.pkl\", \"rb\") as file:\n",
    "        embeddings = pickle.load(file)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "# Initialize variables\n",
    "silhouette_scores = []\n",
    "inertia = []\n",
    "# Loop through different numbers of clusters\n",
    "for i in range(2, 35):  # Start from 2 as silhouette_score needs at least 2 clusters\n",
    "    kmeans = KMeans(n_clusters=i, init='k-means++')\n",
    "    kmeans.fit(embeddings)\n",
    "    cluster_labels = kmeans.labels_\n",
    "    \n",
    "    inertia.append(kmeans.inertia_)\n",
    "    \n",
    "    # Calculate the silhouette score and append to the list\n",
    "    silhouette_avg = silhouette_score(embeddings, cluster_labels)\n",
    "    silhouette_scores.append(silhouette_avg)\n",
    "    # print(f\"For n_clusters = {i}, the silhouette score is {silhouette_avg}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the silhouette scores\n",
    "plt.plot(range(2, 35), silhouette_scores)\n",
    "plt.title('Silhouette Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(range(10, 35), inertia)\n",
    "plt.title('Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
